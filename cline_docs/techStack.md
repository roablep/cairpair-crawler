## Tech Stack for Caregiver Resource Web Crawler

### Core Technologies

*   **Python:** Programming language for the web crawler and data processing.
*   **crawl4ai:** Asynchronous web crawling library for efficient data extraction.
*   **pydantic:** Data validation and settings management using Python type hints.
*   **Groq/deepseek-r1-distill-llama-70b:** Language model for intelligent data extraction.
*   **dotenv:** For managing environment variables (API keys).
*   **csv:** Python library for working with CSV files for data output.
*   **asyncio:** Python library for asynchronous programming.

### Development Environment

*   **VSCode:** Integrated Development Environment (IDE) for code editing and project management.
*   **Conda/venv:** Virtual environment for managing project dependencies.
*   **macOS:** Operating system (user's environment).
*   **zsh:** Default shell (user's environment).

### Libraries and Tools

*   **requests:** (Potentially used by `crawl4ai` for HTTP requests)
*   **BeautifulSoup4 / lxml:** (Potentially used by `crawl4ai` for HTML parsing)
*   **Regular Expressions (re):** For pattern matching in text data.
*   **JSON:** For handling JSON data from LLM extraction.

This tech stack provides a robust foundation for building an efficient and intelligent web crawler for caregiver resources.
